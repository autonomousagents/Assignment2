Took 200 000 000  episodes to converge,
agent = new PredatorQLearning(0,9, 0,5, 0,001, 0,5, PredatorQLearning,ActionSelection,epsilonGreedy, new Position(0, 0));
MSE met die van 11 million: 0,34776

Action = Hor,Approach   
0,0000     
7,8287 8,9869    
7,4359 7,5489 6,7518   
6,0730 6,2427 6,5307 5,1853  
5,6643 6,2768 5,1733 4,9290 4,4022 
4,8737 5,2833 4,8906 4,5663 4,2458 3,8350


Action = Hor,Retreat    
0,0000     
7,7290 6,9895    
6,8435 6,3862 5,3514   
5,7762 5,6432 5,0362 4,3829  
5,1203 5,1129 4,4665 4,1936 3,6470 
4,8210 4,5855 4,1377 3,9038 3,4175 3,4536


Action = Ver,Approach   
0,0000     
9,9998 8,3953    
8,9709 8,2492 7,6672   
7,9692 7,4592 6,0241 5,7674  
6,9035 5,5893 5,6148 4,9699 4,6643 
5,7713 5,1799 4,8598 4,8387 4,1243 3,7715


Action = Ver,Retreat    
0,0000     
7,8313 6,7933    
6,9928 6,3700 5,5051   
6,2632 5,5726 5,2123 4,7863  
5,3505 5,1244 4,7727 4,1406 3,8980 
5,2480 5,1351 4,7033 4,2656 3,7796 3,4055


Action = Wait           
0,0000     
7,6372 7,1247    
6,9133 6,4182 6,7255   
6,7875 5,8166 5,7619 4,9839  
6,1519 5,8043 4,9525 4,6722 4,1803 
5,3701 5,0318 4,4770 4,1881 3,7214 3,4449